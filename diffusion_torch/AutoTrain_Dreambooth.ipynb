{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JvMRbVLEJlZT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.1.7 requires tiktoken<1,>=0.7, but you have tiktoken 0.6.0 which is incompatible.\n",
      "faster-whisper 1.0.1 requires tokenizers<0.16,>=0.13, but you have tokenizers 0.19.1 which is incompatible.\n",
      "langchain-core 0.2.0 requires packaging<24.0,>=23.2, but you have packaging 24.0 which is incompatible.\n",
      "langfuse 2.24.0 requires packaging<24.0,>=23.2, but you have packaging 24.0 which is incompatible.\n",
      "chainlit 1.0.502 requires packaging<24.0,>=23.1, but you have packaging 24.0 which is incompatible.\n",
      "chainlit 1.0.502 requires uvicorn<0.26.0,>=0.25.0, but you have uvicorn 0.29.0 which is incompatible.\n",
      "langchain 0.1.15 requires langchain-core<0.2.0,>=0.1.41, but you have langchain-core 0.2.0 which is incompatible.\n",
      "blendmodes 2022 requires Pillow<10,>=9.0.0, but you have pillow 10.3.0 which is incompatible.\n",
      "langchain-text-splitters 0.0.1 requires langchain-core<0.2.0,>=0.1.28, but you have langchain-core 0.2.0 which is incompatible.\n",
      "langchain-community 0.0.32 requires langchain-core<0.2.0,>=0.1.41, but you have langchain-core 0.2.0 which is incompatible.\n",
      "open-clip-torch 2.20.0 requires protobuf<4, but you have protobuf 4.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#@title ðŸ¤— AutoTrain DreamBooth\n",
    "#@markdown In order to use this colab\n",
    "#@markdown - upload images to a folder named `images/`\n",
    "#@markdown - choose a project name if you wish\n",
    "#@markdown - change model if you wish, you can also select sd2/2.1 or sd1.5\n",
    "#@markdown - update prompt and remember it. choose keywords that don't usually appear in dictionaries\n",
    "#@markdown - add huggingface information (token) if you wish to push trained model to huggingface hub\n",
    "#@markdown - update hyperparameters if you wish\n",
    "#@markdown - click `Runtime > Run all` or run each cell individually\n",
    "#@markdown - report issues / feature requests here: https://github.com/huggingface/autotrain-advanced/issues\n",
    "\n",
    "import os\n",
    "!pip install -U autotrain-advanced > install_logs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "A2-_lkBS1WKA"
   },
   "outputs": [],
   "source": [
    "#@markdown ---\n",
    "#@markdown #### Project Config\n",
    "project_name = 'my-dreambooth-project' # @param {type:\"string\"}\n",
    "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
    "prompt = 'art picture of lucky capibara' # @param {type: \"string\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown #### Push to Hub?\n",
    "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
    "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
    "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
    "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
    "push_to_hub = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
    "hf_token = \"hf_XXX\" #@param {type:\"string\"}\n",
    "hf_username = \"abc\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown #### Hyperparameters\n",
    "learning_rate = 1e-4 # @param {type:\"number\"}\n",
    "num_steps = 500 #@param {type:\"number\"}\n",
    "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
    "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
    "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
    "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
    "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
    "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
    "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
    "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
    "\n",
    "os.environ[\"PROJECT_NAME\"] = project_name\n",
    "os.environ[\"MODEL_NAME\"] = model_name\n",
    "os.environ[\"PROMPT\"] = prompt\n",
    "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
    "os.environ[\"HF_TOKEN\"] = hf_token\n",
    "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
    "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
    "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
    "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
    "os.environ[\"RESOLUTION\"] = str(resolution)\n",
    "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
    "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
    "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
    "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
    "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
    "os.environ[\"HF_USERNAME\"] = hf_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "g3cd_ED_yXXt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
      "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: inference, deploy, func, config, version, train_split, backend, valid_split, train, log, data_path\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mimages/img-3orYs4i9BbTYnG0UkqZOBD4X.png\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mimages/img-84WKRp4eGZOyTitlSWNj54lH.png\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mimages/img-mk95jCuMB5rXFPaGuEA46ifA.png\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mimages/img-a5PUT6hUxpVSpfUNNREziYHe.png\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m360\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'my-dreambooth-project/training_params.json']\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 06:58:54\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'my-dreambooth-project/autotrain-data', 'class_image_path': None, 'prompt': 'art picture of lucky capibara', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'my-dreambooth-project', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': None, 'push_to_hub': False, 'username': 'abc', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
      "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-22 06:58:57\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 401 Client Error. (Request ID: Root=1-664dcff0-76dacfcf77466aa52d0db7fc;e767d41b-85d0-461e-ad0b-3126acc678f6)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/api/datasets/my-dreambooth-project/autotrain-data/revision/main.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated.\n",
      "Invalid username or password.\u001b[0m\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.3.0+cu121 with CUDA 1201 (you have 2.2.2+cu121)\n",
      "    Python  3.11.9 (you have 3.11.8)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "tokenizer/tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 737/737 [00:00<00:00, 11.7MB/s]\n",
      "tokenizer/vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.06M/1.06M [00:00<00:00, 2.47MB/s]\n",
      "tokenizer/merges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 525k/525k [00:00<00:00, 5.44MB/s]\n",
      "tokenizer/special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 472/472 [00:00<00:00, 7.44MB/s]\n",
      "tokenizer_2/tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 725/725 [00:00<00:00, 10.3MB/s]\n",
      "tokenizer_2/special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 460/460 [00:00<00:00, 4.57MB/s]\n",
      "text_encoder/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 565/565 [00:00<00:00, 5.62MB/s]\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "text_encoder_2/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 620kB/s]\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "model_index.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 609/609 [00:00<00:00, 6.16MB/s]\n",
      "scheduler/scheduler_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 479/479 [00:00<00:00, 4.90MB/s]\n",
      "{'dynamic_thresholding_ratio', 'rescale_betas_zero_snr', 'clip_sample_range', 'variance_type', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
      "text_encoder/model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 492M/492M [00:11<00:00, 42.0MB/s]\n",
      "text_encoder_2/model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 2.78G/2.78G [01:05<00:00, 42.4MB/s]\n",
      "vae/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 642/642 [00:00<00:00, 8.39MB/s]\n",
      "vae/diffusion_pytorch_model.safetensors: 100%|â–ˆ| 335M/335M [00:08<00:00, 40.9MB/\n",
      "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "unet/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.68k/1.68k [00:00<00:00, 17.8MB/s]\n",
      "unet/diffusion_pytorch_model.safetensors: 100%|â–ˆ| 10.3G/10.3G [04:16<00:00, 40.0\n",
      "{'reverse_transformer_layers_per_block', 'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 07:04:58\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 07:04:58\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 4\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 07:04:58\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 4\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 07:04:58\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 500\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 07:04:58\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 07:04:58\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 07:04:58\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 07:04:58\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [29:29<00:00,  3.51s/it, loss=0.00548, lr=0.0001]Model weights saved in my-dreambooth-project/pytorch_lora_weights.safetensors\n",
      "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [29:29<00:00,  3.54s/it, loss=0.00548, lr=0.0001]\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 07:34:28\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-22 07:34:29\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m393\u001b[0m - \u001b[1mJob ID: 923532\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!autotrain dreambooth \\\n",
    "--model ${MODEL_NAME} \\\n",
    "--project-name ${PROJECT_NAME} \\\n",
    "--image-path images/ \\\n",
    "--prompt \"${PROMPT}\" \\\n",
    "--resolution ${RESOLUTION} \\\n",
    "--batch-size ${BATCH_SIZE} \\\n",
    "--num-steps ${NUM_STEPS} \\\n",
    "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
    "--lr ${LEARNING_RATE} \\\n",
    "--mixed-precision ${MIXED_PRECISION} \\\n",
    "--username ${HF_USERNAME} \\\n",
    "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
    "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
    "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
    "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
    "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "_LvIS7-7PcLT"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d19464ff33465dad0d30aa93243793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e53611c09884ba0b39d7da46b1d14f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5684c6b443f742789a3edee1caa5a058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7f52e1e621464ca9a15795f507db5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference\n",
    "# this is the inference code that you can use after you have trained your model\n",
    "# Unhide code below and change prj_path to your repo or local path (e.g. my_dreambooth_project)\n",
    "#\n",
    "#\n",
    "#\n",
    "from diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "import torch\n",
    "\n",
    "prj_path = \"my-dreambooth-Capibara\"\n",
    "model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    model,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "pipe.to(\"cuda\")\n",
    "pipe.load_lora_weights(prj_path, weight_name=\"pytorch_lora_weights.safetensors\")\n",
    "\n",
    "refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "refiner.to(\"cuda\")\n",
    "\n",
    "prompt = \"\"\"You find yourself in a lush forest.\n",
    "the trees towering above you like sentinels.\n",
    "The canopy is a kaleidoscope of greens, with sunlight filtering through in dappled patterns.\n",
    "A gentle breeze rustles the leaves, and the sounds of birdsong fill the air.\n",
    "in the distance two small \"lucky capybara\" are playing on the lawn.\n",
    "\"\"\"\n",
    "\n",
    "seed = 128\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "image = pipe(prompt=prompt, generator=generator).images[0]\n",
    "image = refiner(prompt=prompt, generator=generator, image=image).images[0]\n",
    "image.save(f\"generated_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.8\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
